{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ecc1f0",
   "metadata": {},
   "source": [
    "# Explore Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cfb07b",
   "metadata": {},
   "source": [
    "In this section, we will explore the basic mlflow tracking APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b96009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import mlflow library\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcaa8a",
   "metadata": {},
   "source": [
    "We start by setting the tracking URI to `http://localhost:5000` for this experiment session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351625dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbf607",
   "metadata": {},
   "source": [
    "Now, let's create our first experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6794b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = mlflow.create_experiment(\"Dummy Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095e4b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'107041076032827412'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc39c04",
   "metadata": {},
   "source": [
    "Next, we'll start a run using the `with` statement called \"DecisionTree\", attach it to our previous experiment, and log the following:\n",
    "- parameters:\n",
    "    - n_estimators: 10\n",
    "    - criterion: 'gini'\n",
    "    - max_depth: 5\n",
    "- metrics:\n",
    "    - accuracy\n",
    "    - f1 score\n",
    "- tags:\n",
    "    - vesrsion\n",
    "    - task name\n",
    "    - model name\n",
    "- artifact:\n",
    "    - artifact.txt file\n",
    "\n",
    "Know that if you don’t set the experiment, the runs will be attached to the default experiment.\n",
    "\n",
    "Also, if you don’t specify the run name it’ll be assigned a weird names e.g. brawny-sheep-364."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01007f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=exp_id, run_name='DecisionTree') as run:\n",
    "    n_estimators = 10\n",
    "    criterion = 'gini'\n",
    "    max_depth = 5\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", 0.2888)\n",
    "    mlflow.log_metric(\"f1_score\", 0.7888)\n",
    "    mlflow.set_tag(\"version\", \"1.3\")\n",
    "    mlflow.set_tag(\"model\", \"DecisionTree\")\n",
    "\n",
    "    artifact_path = r\"./artifact.txt\"\n",
    "    with open(artifact_path, \"w\") as f:\n",
    "        f.write(\"This is a test file for MLflow artifact logging.\")\n",
    "\n",
    "    mlflow.log_artifact(artifact_path, artifact_path=\"artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc7459",
   "metadata": {},
   "source": [
    "Note: after logging the artifact file, the logged file won't get affected by any new changes.\n",
    "\n",
    "Additionally, at a run if you specify the same id of an existing run, it’ll be overridden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fc995",
   "metadata": {},
   "source": [
    "After creating our experiment, let's check the MLflow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbad60",
   "metadata": {},
   "source": [
    "You'll notice that the user name is the machine default user name.  \n",
    "However, this can be changed by setting the environment variable `LOGNAME` to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064f220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOGNAME\"] = \"Heba\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf451a",
   "metadata": {},
   "source": [
    "With the username change let's try to run the previous run again. \n",
    "This time we'll use the `mlflow.start_run` & `mlflow.end_run`. Also, instead of logging each parameter or metric separatly, we can log them all once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b60883",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run(experiment_id=exp_id, run_name='DecisionTree 2')\n",
    "n_estimators = 10\n",
    "criterion = 'gini'\n",
    "max_depth = 5\n",
    "\n",
    "# mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "# mlflow.log_param(\"criterion\", criterion)\n",
    "# mlflow.log_param(\"max_depth\", max_depth)\n",
    "mlflow.log_params({\"n_estimators\": n_estimators, \"criterion\": criterion, \"max_depth\": max_depth})\n",
    "\n",
    "# mlflow.log_metric(\"metric1\", 0.2888)\n",
    "# mlflow.log_metric(\"metric2\", 0.7888)\n",
    "mlflow.log_metrics({\"accuracy\": 0.8888, \"f1_score\": 0.9888})\n",
    "\n",
    "mlflow.set_tags({\"version\": \"1.3\", \"model\": \"DecisionTree\", \"task\": \"classification\"})\n",
    "\n",
    "artifact_path = r\"./artifact.txt\"\n",
    "with open(artifact_path, \"w\") as f:\n",
    "    f.write(\"This is a test file for MLflow artifact logging.\")\n",
    "\n",
    "mlflow.log_artifact(artifact_path, artifact_path=\"artifacts\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f2957",
   "metadata": {},
   "source": [
    "But what if we restarted the kenrel and the `exp_id` got lost and we wanted to run another run?  \n",
    "Upon running the previous cells, we'd get an error at the experiment creation cell as each experiment shall have a unique name. Hence, it's easier to use `mlflow.set_experiment()`.\n",
    "\n",
    "On the other hand you can have multiple runs with the same name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ee396",
   "metadata": {},
   "source": [
    "Try to run multiple runs to check the ui capabailties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d630c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12524648",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    run = mlflow.start_run(experiment_id=exp_id, run_name='DecisionTree')\n",
    "    n_estimators = random.choice(range(5, 20))\n",
    "    criterion = random.choice([\"gini\", \"entropy\", \"log_loss\"])\n",
    "    max_depth = random.choice(range(5, 20))\n",
    "\n",
    "    mlflow.log_params({\"n_estimators\": n_estimators, \"criterion\": criterion, \"max_depth\": max_depth})\n",
    "    \n",
    "    mlflow.log_metrics({\"accuracy\": random.random(), \"f1_score\": random.random()})\n",
    "\n",
    "    mlflow.set_tags({\"version\": f\"1.{i}\", \"model\": \"DecisionTree\", \"task\": \"classification\"})\n",
    "\n",
    "\n",
    "    artifact_path = r\"./artifact.txt\"\n",
    "    with open(artifact_path, \"w\") as f:\n",
    "        f.write(f\"This is a test file for MLflow artifact logging. No. {i}\")\n",
    "\n",
    "    mlflow.log_artifact(artifact_path, artifact_path=\"artifacts\")\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714c8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
